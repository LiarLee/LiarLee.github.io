---
title: Cilium è¸©å‘æ€»ç»“
date: 2022-08-19 22:21:48
category: Kubernetes
tags:
  - Kubernetes
  - Cilium
  - EKS
---
# æµ‹è¯•ç¯å¢ƒ

- **KVM**  - hayden@HaydenArchDesktop ~> virsh version
>  Compiled against library: libvirt 8.6.0
>  Using library: libvirt 8.6.0
>  Using API: QEMU 8.6.0
>  Running hypervisor: QEMU 7.0.0

- **VM OS**ï¼š root@fedora ~# cat /etc/os-release
>  NAME="Fedora Linux"
>  VERSION="36 (Thirty Six)"
>  ID=fedora
>  VERSION_ID=36

- **KVM** è™šæ‹Ÿæœºä¸¤å°
>  - Masterï¼š hostname: fedora
>  - Nodeï¼š hostname: knode1

- **kubernetes ç‰ˆæœ¬**ï¼š v1.24.3

- **kubernetes å®‰è£…æ–¹å¼**ï¼š kubeadm 

- **dockerç‰ˆæœ¬**:  docker://20.10.17 
> NOTE: (å°è¯•ä½¿ç”¨Containerdï¼Œ ä½†æ˜¯ç¿»è½¦äº†ï¼Œ æ§åˆ¶å¹³é¢çš„Podå¯åŠ¨ä¸äº†ï¼Œ æ‰€ä»¥æ”¾å¼ƒäº†ï¼Œé‚ä½¿ç”¨CRI-Dockerdï¼Œé…ç½®äº†Docker runtimeï¼Œ Containerdä½¿ç”¨é»˜è®¤çš„å‚æ•°æ— æ³•æ­£å¸¸çš„å¯åŠ¨ï¼Œ çœ‹èµ·æ¥å³ä½¿çœŸçš„å‡çº§åˆ°äº†1.24 è¿ç§»è¿˜æ˜¯ä¸€ä¸ªé—®é¢˜)

- **Kernel Version**: 5.17.5-300.fc36.x86_64

# Helmå‚æ•°
å¦‚æœæ˜¯åœ¨KVMå¯åŠ¨çš„è™šæ‹Ÿæœºï¼Œå¯ä»¥é€šè¿‡è¿™ä¸ªå®‰è£…å‚æ•°æ¥å¼€å¯æ›´å¤šåŠŸèƒ½ï¼Œä½†æ˜¯å—é™äºæˆ‘çš„KVMè™šæ‹Ÿç½‘å¡é©±åŠ¨ä¸èƒ½attach xdp ç¨‹åºï¼Œ æ‰€ä»¥ã€‚ã€‚ã€‚ã€‚xdp åŠ é€Ÿæ— æ³•å¯ç”¨ï¼Œä½†æ˜¯å…¶ä»–çš„é«˜çº§ç‰¹æ€§å‡å¯å¼€å¯ï¼Œ é›†ç¾¤çŠ¶æ€æ­£å¸¸ã€‚

```shell
helm upgrade -i cilium cilium/cilium \
  --namespace kube-system \
  --set tunnel=disabled \
  --set autoDirectNodeRoutes=true \
  --set loadBalancer.mode=dsr \
  --set kubeProxyReplacement=strict \
  --set enableIPv4Masquerade=false \
  --set loadBalancer.algorithm=maglev \
  --set devices=enp1s0 \
  --set k8sServiceHost=192.168.31.100 \
  --set k8sServicePort=6443 \
  --set hubble.relay.enabled=true \
  --set hubble.ui.enabled=true
```
# Cilium Cli
touch ./install_cilium_cli.sh
```shell
CILIUM_CLI_VERSION=$(curl -s https://raw.githubusercontent.com/cilium/cilium-cli/main/stable.txt)
CLI_ARCH=amd64
if [ "$(uname -m)" = "aarch64" ]; then CLI_ARCH=arm64; fi
curl -L --fail --remote-name-all https://github.com/cilium/cilium-cli/releases/download/${CILIUM_CLI_VERSION}/cilium-linux-${CLI_ARCH}.tar.gz{,.sha256sum}
sha256sum --check cilium-linux-${CLI_ARCH}.tar.gz.sha256sum
sudo tar xzvfC cilium-linux-${CLI_ARCH}.tar.gz /usr/local/bin
rm cilium-linux-${CLI_ARCH}.tar.gz{,.sha256sum}
```
# Hubble Cli
touch ./install_hubble_client.sh
```shell
HUBBLE_VERSION=$(curl -s https://raw.githubusercontent.com/cilium/hubble/master/stable.txt)
HUBBLE_ARCH=amd64
if [ "$(uname -m)" = "aarch64" ]; then HUBBLE_ARCH=arm64; fi
curl -L --fail --remote-name-all https://github.com/cilium/hubble/releases/download/$HUBBLE_VERSION/hubble-linux-${HUBBLE_ARCH}.tar.gz{,.sha256sum}
sha256sum --check hubble-linux-${HUBBLE_ARCH}.tar.gz.sha256sum
sudo tar xzvfC hubble-linux-${HUBBLE_ARCH}.tar.gz /usr/local/bin
rm hubble-linux-${HUBBLE_ARCH}.tar.gz{,.sha256sum}
```

## Cilium Cli å®‰è£…æ’ä»¶å‘½ä»¤
```shell
cilium upgrade # åŸåœ°å‡çº§

# å®‰è£…å¹¶ç›´æ¥æ›¿æ¢kubeproxy
cilium install --version 1.14.1 --set kubeProxyReplacement=true --set=ipam.operator.clusterPoolIPv4PodCIDRList="10.42.0.0/16" --set k8sServiceHost=kube3s.liarlee.site --set k8sServicePort=6443




# å‡çº§
hayden@arch ~> cilium upgrade
ğŸ”® Auto-detected Kubernetes kind: K3s
â„¹ï¸  Using Cilium version 1.14.2
ğŸ”® Auto-detected cluster name: default

# çœ‹çŠ¶æ€
cilium status
# ä½¿ç”¨hubble
cilium hubble port-forward &

cilium hubble enable --ui

hubble observe --since=1m -t l7 -


```
---

# ç‰¹æ€§ä»¥åŠçŠ¶æ€æ£€æŸ¥

é»˜è®¤çš„å®‰è£…å®Œæˆä¹‹åå¼€å¯ç‰¹æ€§å¦‚ä¸‹ï¼š

1. Kubeproxy Bypass
2. Iptables Bypass
3. LoadBalancer ç®—æ³•ï¼š Meglav
4. LoadBalancer ç‰¹æ€§ï¼š DSR
5. æŠ¥æ–‡Masquerade å°è£…ï¼š Disabled
6. Hubble ï¼š Enable
7. éš§é“å°åŒ…ï¼š Disabled

---

ä¸‹é¢æ˜¯ CIlium Statusçš„å‘½ä»¤è¿”å›ç»“æœï¼š

```bash
root@fedora ~# cilium status
    /Â¯Â¯\
 /Â¯Â¯\__/Â¯Â¯\    Cilium:         OK
 \__/Â¯Â¯\__/    Operator:       OK
 /Â¯Â¯\__/Â¯Â¯\    Hubble:         OK
 \__/Â¯Â¯\__/    ClusterMesh:    disabled
    \__/

Deployment        cilium-operator    Desired: 2, Ready: 2/2, Available: 2/2
Deployment        hubble-relay       Desired: 1, Ready: 1/1, Available: 1/1
DaemonSet         cilium             Desired: 2, Ready: 2/2, Available: 2/2
Deployment        hubble-ui          Desired: 1, Ready: 1/1, Available: 1/1
Containers:       hubble-relay       Running: 1
                  hubble-ui          Running: 1
                  cilium             Running: 2
                  cilium-operator    Running: 2
Cluster Pods:     14/14 managed by Cilium
Image versions    hubble-ui          quay.io/cilium/hubble-ui:v0.9.0@sha256:0ef04e9a29212925da6bdfd0ba5b581765e41a01f1cc30563cef9b30b457fea0: 1
                  hubble-ui          quay.io/cilium/hubble-ui-backend:v0.9.0@sha256:000df6b76719f607a9edefb9af94dfd1811a6f1b6a8a9c537cba90bf12df474b: 1
                  cilium             quay.io/cilium/cilium:v1.12.0@sha256:079baa4fa1b9fe638f96084f4e0297c84dd4fb215d29d2321dcbe54273f63ade: 2
                  cilium-operator    quay.io/cilium/operator-generic:v1.12.0@sha256:bb2a42eda766e5d4a87ee8a5433f089db81b72dd04acf6b59fcbb445a95f9410: 2
                  hubble-relay       quay.io/cilium/hubble-relay:v1.12.0@sha256:ca8033ea8a3112d838f958862fa76c8d895e3c8d0f5590de849b91745af5ac4d: 1
```

ds/cilium ä¸­çš„å‘½ä»¤è¿”å›ç»“æœï¼š

```bash
root@fedora:/home/cilium# cilium status
KVStore:                 Ok   Disabled
Kubernetes:              Ok   1.24 (v1.24.3) [linux/amd64]
Kubernetes APIs:         ["cilium/v2::CiliumClusterwideNetworkPolicy", "cilium/v2::CiliumEndpoint", "cilium/v2::CiliumNetworkPolicy", "cilium/v2::CiliumNode", "core/v1::Namespace", "core/v1::Node", "core/v1::Pods", "core/v1::Service", "discovery/v1::EndpointSlice", "networking.k8s.io/v1::NetworkPolicy"]
KubeProxyReplacement:    Strict   [enp1s0 192.168.31.100 (Direct Routing)]
Host firewall:           Disabled
CNI Chaining:            none
Cilium:                  Ok   1.12.0 (v1.12.0-9447cd1)
NodeMonitor:             Listening for events on 4 CPUs with 64x4096 of shared memory
Cilium health daemon:    Ok
IPAM:                    IPv4: 3/254 allocated from 10.0.0.0/24,
BandwidthManager:        Disabled
Host Routing:            BPF
Masquerading:            Disabled
Controller Status:       23/23 healthy
Proxy Status:            OK, ip 10.0.0.78, 0 redirects active on ports 10000-20000
Global Identity Range:   min 256, max 65535
Hubble:                  Ok   Current/Max Flows: 283/4095 (6.91%), Flows/s: 1.62   Metrics: Disabled
Encryption:              Disabled
Cluster health:          2/2 reachable   (2022-08-23T01:57:33Z)
```

Cilium verboseçš„è¯¦ç»†ç»“æœï¼š

```bash
root@fedora:/home/cilium# cilium status --verbose
KVStore:                Ok   Disabled
Kubernetes:             Ok   1.24 (v1.24.3) [linux/amd64]
Kubernetes APIs:        ["cilium/v2::CiliumClusterwideNetworkPolicy", "cilium/v2::CiliumEndpoint", "cilium/v2::CiliumNetworkPolicy", "cilium/v2::CiliumNode", "core/v1::Namespace", "core/v1::Node", "core/v1::Pods", "core/v1::Service", "discovery/v1::EndpointSlice", "networking.k8s.io/v1::NetworkPolicy"]
KubeProxyReplacement:   Strict   [enp1s0 192.168.31.100 (Direct Routing)]
Host firewall:          Disabled
CNI Chaining:           none
Cilium:                 Ok   1.12.0 (v1.12.0-9447cd1)
NodeMonitor:            Listening for events on 4 CPUs with 64x4096 of shared memory
Cilium health daemon:   Ok
IPAM:                   IPv4: 3/254 allocated from 10.0.0.0/24,
Allocated addresses:
  10.0.0.11 (kube-system/coredns-6d4b75cb6d-tbgrr)
  10.0.0.201 (health)
  10.0.0.78 (router)
BandwidthManager:       Disabled
Host Routing:           BPF
Masquerading:           Disabled
Clock Source for BPF:   ktime
Controller Status:      23/23 healthy
  Name                                  Last success   Last error   Count   Message
  cilium-health-ep                      29s ago        never        0       no error
  dns-garbage-collector-job             34s ago        never        0       no error
  endpoint-1313-regeneration-recovery   never          never        0       no error
  endpoint-2868-regeneration-recovery   never          never        0       no error
  endpoint-2945-regeneration-recovery   never          never        0       no error
  endpoint-gc                           3m34s ago      never        0       no error
  ipcache-inject-labels                 3m30s ago      3m33s ago    0       no error
  k8s-heartbeat                         4s ago         never        0       no error
  link-cache                            15s ago        never        0       no error
  metricsmap-bpf-prom-sync              4s ago         never        0       no error
  resolve-identity-1313                 3m29s ago      never        0       no error
  resolve-identity-2868                 3m29s ago      never        0       no error
  resolve-identity-2945                 3m30s ago      never        0       no error
  sync-endpoints-and-host-ips           30s ago        never        0       no error
  sync-lb-maps-with-k8s-services        3m30s ago      never        0       no error
  sync-node-with-ciliumnode (fedora)    3m32s ago      3m33s ago    0       no error
  sync-policymap-1313                   26s ago        never        0       no error
  sync-policymap-2868                   26s ago        never        0       no error
  sync-policymap-2945                   26s ago        never        0       no error
  sync-to-k8s-ciliumendpoint (1313)     9s ago         never        0       no error
  sync-to-k8s-ciliumendpoint (2868)     9s ago         never        0       no error
  sync-to-k8s-ciliumendpoint (2945)     0s ago         never        0       no error
  template-dir-watcher                  never          never        0       no error
Proxy Status:            OK, ip 10.0.0.78, 0 redirects active on ports 10000-20000
Global Identity Range:   min 256, max 65535
Hubble:                  Ok   Current/Max Flows: 377/4095 (9.21%), Flows/s: 1.67   Metrics: Disabled
KubeProxyReplacement Details:
  Status:                 Strict
  Socket LB:              Enabled
  Socket LB Protocols:    TCP, UDP
  Devices:                enp1s0 192.168.31.100 (Direct Routing)
  Mode:                   DSR
  Backend Selection:      Maglev (Table Size: 16381)
  Session Affinity:       Enabled
  Graceful Termination:   Enabled
  NAT46/64 Support:       Disabled
  XDP Acceleration:       Disabled
  Services:
  - ClusterIP:      Enabled
  - NodePort:       Enabled (Range: 30000-32767)
  - LoadBalancer:   Enabled
  - externalIPs:    Enabled
  - HostPort:       Enabled
BPF Maps:   dynamic sizing: on (ratio: 0.002500)
  Name                          Size
  Non-TCP connection tracking   65536
  TCP connection tracking       131072
  Endpoint policy               65535
  Events                        4
  IP cache                      512000
  IP masquerading agent         16384
  IPv4 fragmentation            8192
  IPv4 service                  65536
  IPv6 service                  65536
  IPv4 service backend          65536
  IPv6 service backend          65536
  IPv4 service reverse NAT      65536
  IPv6 service reverse NAT      65536
  Metrics                       1024
  NAT                           131072
  Neighbor table                131072
  Global policy                 16384
  Per endpoint policy           65536
  Session affinity              65536
  Signal                        4
  Sockmap                       65535
  Sock reverse NAT              65536
  Tunnel                        65536
Encryption:            Disabled
Cluster health:        2/2 reachable    (2022-08-23T01:59:33Z)
  Name                 IP               Node        Endpoints
  fedora (localhost)   192.168.31.100   reachable   reachable
  knode1               192.168.31.101   reachable   reachable
```

cilium-health status --probe ä¹‹åçš„ç»“æœï¼Œ å¤šä¸ªèŠ‚ç‚¹ä¹‹é—´çš„è”é€šæ€§æ­£å¸¸ï¼š

```bash
root@fedora:/home/cilium# cilium-health status --probe
Probe time:   2022-08-23T02:01:04Z
Nodes:
  fedora (localhost):
    Host connectivity to 192.168.31.100:
      ICMP to stack:   OK, RTT=140.825Âµs
      HTTP to agent:   OK, RTT=199.54Âµs
    Endpoint connectivity to 10.0.0.201:
      ICMP to stack:   OK, RTT=128.2Âµs
      HTTP to agent:   OK, RTT=263.034Âµs
  knode1:
    Host connectivity to 192.168.31.101:
      ICMP to stack:   OK, RTT=235.981Âµs
      HTTP to agent:   OK, RTT=330.706Âµs
    Endpoint connectivity to 10.0.1.251:
      ICMP to stack:   OK, RTT=177.807Âµs
      HTTP to agent:   OK, RTT=275.869Âµs
```

æ²¡æœ‰æ‰§è¡ŒCilium connectivity Testï¼Œ è¿™ä¸ªæµ‹è¯•å’Œ 1.1.1.1:443 çš„æµ‹è¯•åœ¨åŸºæœ¬ä¸Šæ¯æ¬¡éƒ½æ˜¯å¤±è´¥çš„ã€‚ç›®å‰åŸå› è¿˜ä¸æ¸…æ¥šï¼Œ æ²¡è°ƒæŸ¥ï¼Œä½†æ˜¯é›†ç¾¤å†…çš„Podè®¿é—®å¤–éƒ¨çš„ç½‘ç»œæ˜¯å®Œå…¨æ­£å¸¸çš„ã€‚ 

åŸºäºAWS EC2 æµ‹è¯•çš„ç»“æœï¼ˆæ— æ³•å…³é—­ Masquerade ä»¥åŠ ç»•è¿‡ Iptablesï¼‰ï¼Œ ä¸flannelç›¸æ¯”ï¼ŒCiliumå½“å‰çš„æ€§èƒ½è¿˜æ˜¯å°‘å°‘å·®ä¸€ç‚¹ç‚¹ï¼Œä½†æ˜¯è·¨è¶Šå…¬ç½‘è®¿é—®çš„ç¨³å®šæ€§æ›´å¼ºï¼ŒHTTPå®Œå…¨æ²¡æœ‰Failedè¯·æ±‚ã€‚

æ²¡æœ‰å¼€å¯XDPï¼Œ åŸå› æ˜¯æˆ‘ä½¿ç”¨çš„æ˜¯KVMçš„è™šæ‹Ÿæœº ï¼Œä½¿ç”¨çš„é©±åŠ¨ç¨‹åºæ˜¯VirtIOï¼Œ çœ‹èµ·æ¥è¿™ä¸ªé©±åŠ¨åœ¨æˆ‘å½“å‰ç‰ˆæœ¬çš„è™šæ‹ŸåŒ–é‡Œé¢å¯èƒ½éœ€è¦åšä¸€äº›ç‰¹æ®Šçš„è®¾ç½®æ‰èƒ½å¼€å¯ï¼Œ æˆ‘æ²¡æœ‰ç»§ç»­è¿›è¡Œæµ‹è¯•ã€‚

ç›®å‰ä¹Ÿæ²¡æ³•å¯¹æ€§èƒ½åšä»»ä½•çš„å¯¹æ¯”æµ‹è¯•ï¼Œ  æ²¡æœ‰æ¡ä»¶å¯åŠ¨ä¸¤ä¸ªé›†ç¾¤åšå¯¹æ¯”ï¼Œå¯ä»¥æƒ³è§å› ä¸ºåº•å±‚çš„å“åº”æ—¶é—´æå¿«ï¼Œæ‰€ä»¥æ²¡æœ‰åŠæ³•çœ‹å‡ºå·®è·ï¼› è¦ä¹ˆå°±æ˜¯èµ„æºçš„æŠ¢å å¯¼è‡´æœ¬èº«çš„æµ‹è¯•ç»“æœä¸å¤Ÿç¨³å®šã€‚

æˆ‘ç›®å‰è¿˜åœ¨ EC2 ä»¥åŠ EKS ä¸­è°ƒè¯•ï¼š

1. EKSï¼šAWS CNIæ›¿æ¢æ‰ä¹‹åæœ‰è‡ªå·±çš„é—®é¢˜ï¼Œ ä¸èƒ½å¼€å¯å®Œå…¨çš„Iptables Bypassï¼Œ ç”±äºå¯ç”¨äº†ENI MODE å°±ä¼šæä¾› EndpointRouteï¼Œ æ„Ÿè§‰è¿™å·²ç»æ˜¯BypassIptablesï¼Œ ä½†æ˜¯æ²¡èƒ½éªŒè¯ï¼Œä¸ç¡®å®šã€‚

2. EC2 éƒ¨ç½²çš„ Kubernetesï¼š é›†ç¾¤ä¸èƒ½å¼€å¯HostRoutingï¼Œ å¼€å¯ä¹‹åcilium-health status æ— æ³•å®Œæˆå¯¹ç«¯èŠ‚ç‚¹ä¸Šé¢Endpointçš„æ£€æŸ¥ï¼Œ Connection Timeoutã€‚ä¹Ÿä¸èƒ½å®Œå…¨workã€‚

# å…¶ä»–èµ„æ–™

> å…¶ä»–å…¬å¸ä¸šåŠ¡çš„é…ç½®ä»¥åŠæµ‹è¯•ã€‚
>
> https://www.ebpf.top/post/cilium-standalone-L4LB-XDP-zh/
>
> æŒ‰ç…§LinuxåŸºé‡‘ä¼šçš„PPTä¸­æè¿°ï¼Œ KVM è™šæ‹ŸåŒ–æ¡ä»¶ä¸‹ä¹Ÿæ˜¯å¯ä»¥å¼€å¯XDPçš„ï¼Œä½†æ˜¯æˆ‘åªæ˜¯æµ‹è¯•ï¼Œ å°±ä¸æŠ˜è…¾äº†ï¼Œ æˆ‘è‡ªå·±çš„PC æ•ˆæœä¸ä¸€å®šæ˜æ˜¾ã€‚
>
> https://events19.linuxfoundation.cn/wp-content/uploads/2017/11/Accelerating-VM-Networking-through-XDP_Jason-Wang.pdf 
>
> https://lore.kernel.org/bpf/b41ab0f0-4537-74b5-d7c3-b20ce082bdd6@redhat.com/T/
>
> https://lwn.net/Articles/841755/
>
> 
## å¯ç”¨ Bandwidth Manager å’Œ BBR
```shell
# å°è¯•æ·»åŠ äº†bbr ç®—æ³•çš„é€‰é¡¹ï¼Œ ä½¿ç”¨å¦‚ä¸‹å‘½ä»¤è¿›è¡Œå˜æ›´ï¼š 
cilium upgrade --version 1.14.5 --set kubeProxyReplacement=true --set=ipam.operator.clusterPoolIPv4PodCIDRList="10.42.0.0/16" --set k8sServiceHost=kube3s.liarlee.site --set k8sServicePort=6443 --set bandwidthManager.enabled=true --set bandwidthManager.bbr=true

# ä½¿ç”¨å¦‚ä¸‹çš„å‘½ä»¤è¿›è¡Œç¡®è®¤ï¼š
kubectl -n kube-system exec ds/cilium -- cilium status | grep BandwidthManager
```